{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d91a0a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "import os, sys\n",
    "# add parent directory to path\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from model import TimeSeriesDataset, TimeSeriesTransformer, TimeSeriesTransformerRotary, WorldModel\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9f3fce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'val', 'test', 'mean', 'std'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('/abiomed/downsampled/10min_1hr_all_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(data.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8972c979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /abiomed/downsampled/10min_1hr_all_data.pkl\n",
      "Data keys: dict_keys(['train', 'val', 'test', 'mean', 'std'])\n",
      "Train data shape: torch.Size([12051, 12, 13])\n",
      "Val data shape: torch.Size([1938, 12, 13])\n",
      "Test data shape: torch.Size([3876, 12, 13])\n",
      "Number of features: 13\n",
      "\n",
      "Creating WorldModel with rotary transformer...\n",
      "time series transformer device cuda:1\n",
      "Model created with 12 input features\n",
      "Input horizon: 6, Forecast horizon: 6\n",
      "\n",
      "Loading data into the model...\n",
      "loaded datasets with length \n",
      " train:  12051 \n",
      " val:  1938 \n",
      " test:  3876\n",
      "Data loaded successfully!\n",
      "\n",
      "Starting training with:\n",
      "Epochs: 100\n",
      "Batch size: 64\n",
      "Learning rate: 0.001\n",
      "\n",
      "Training the model...\n",
      "New best model with val loss: 0.1204\n",
      "Epoch 1/100 | Train Loss: 0.1777 | Val Loss: 0.1204 | Val MAPE: 0.2282\n",
      "MSE: 0.12042656540870667\n",
      "MAPE: 2.725\n",
      "New best model with val loss: 0.1186\n",
      "Epoch 2/100 | Train Loss: 0.1271 | Val Loss: 0.1186 | Val MAPE: 0.2208\n",
      "Epoch 3/100 | Train Loss: 0.1177 | Val Loss: 0.1210 | Val MAPE: 0.2317\n",
      "New best model with val loss: 0.1113\n",
      "Epoch 4/100 | Train Loss: 0.1152 | Val Loss: 0.1113 | Val MAPE: 0.2242\n",
      "Epoch 5/100 | Train Loss: 0.1131 | Val Loss: 0.1136 | Val MAPE: 0.2150\n",
      "Epoch 6/100 | Train Loss: 0.1114 | Val Loss: 0.1117 | Val MAPE: 0.2104\n",
      "New best model with val loss: 0.1089\n",
      "Epoch 7/100 | Train Loss: 0.1105 | Val Loss: 0.1089 | Val MAPE: 0.2124\n",
      "New best model with val loss: 0.1086\n",
      "Epoch 8/100 | Train Loss: 0.1084 | Val Loss: 0.1086 | Val MAPE: 0.2105\n",
      "New best model with val loss: 0.1052\n",
      "Epoch 9/100 | Train Loss: 0.1083 | Val Loss: 0.1052 | Val MAPE: 0.2039\n",
      "Epoch 10/100 | Train Loss: 0.1065 | Val Loss: 0.1103 | Val MAPE: 0.2191\n",
      "Epoch 11/100 | Train Loss: 0.1068 | Val Loss: 0.1082 | Val MAPE: 0.2087\n",
      "MSE: 0.10815484076738358\n",
      "MAPE: 2.366\n",
      "New best model with val loss: 0.1037\n",
      "Epoch 12/100 | Train Loss: 0.1065 | Val Loss: 0.1037 | Val MAPE: 0.2114\n",
      "Epoch 13/100 | Train Loss: 0.1054 | Val Loss: 0.1038 | Val MAPE: 0.2120\n",
      "Epoch 14/100 | Train Loss: 0.1043 | Val Loss: 0.1325 | Val MAPE: 0.2176\n",
      "Epoch 15/100 | Train Loss: 0.1068 | Val Loss: 0.1101 | Val MAPE: 0.2319\n",
      "Epoch 16/100 | Train Loss: 0.1055 | Val Loss: 0.1072 | Val MAPE: 0.2206\n",
      "Epoch 17/100 | Train Loss: 0.1046 | Val Loss: 0.1052 | Val MAPE: 0.2072\n",
      "Epoch 18/100 | Train Loss: 0.1031 | Val Loss: 0.1058 | Val MAPE: 0.2072\n",
      "Epoch 19/100 | Train Loss: 0.1028 | Val Loss: 0.1071 | Val MAPE: 0.2088\n",
      "Epoch 20/100 | Train Loss: 0.1031 | Val Loss: 0.1077 | Val MAPE: 0.2187\n",
      "Epoch 21/100 | Train Loss: 0.1026 | Val Loss: 0.1044 | Val MAPE: 0.2141\n",
      "MSE: 0.10440821200609207\n",
      "MAPE: 2.449\n",
      "Epoch 22/100 | Train Loss: 0.1023 | Val Loss: 0.1067 | Val MAPE: 0.2119\n",
      "Epoch 23/100 | Train Loss: 0.1016 | Val Loss: 0.1056 | Val MAPE: 0.2149\n",
      "Epoch 24/100 | Train Loss: 0.1002 | Val Loss: 0.1083 | Val MAPE: 0.2115\n",
      "Epoch 25/100 | Train Loss: 0.1002 | Val Loss: 0.1159 | Val MAPE: 0.2171\n",
      "Epoch 26/100 | Train Loss: 0.1021 | Val Loss: 0.1046 | Val MAPE: 0.2101\n",
      "Epoch 27/100 | Train Loss: 0.1001 | Val Loss: 0.1057 | Val MAPE: 0.2173\n",
      "Epoch 28/100 | Train Loss: 0.1003 | Val Loss: 0.1078 | Val MAPE: 0.2200\n",
      "New best model with val loss: 0.1035\n",
      "Epoch 29/100 | Train Loss: 0.0999 | Val Loss: 0.1035 | Val MAPE: 0.2062\n",
      "Epoch 30/100 | Train Loss: 0.0985 | Val Loss: 0.1076 | Val MAPE: 0.2158\n",
      "Epoch 31/100 | Train Loss: 0.0973 | Val Loss: 0.1107 | Val MAPE: 0.2177\n",
      "MSE: 0.11072646826505661\n",
      "MAPE: 2.369\n",
      "Epoch 32/100 | Train Loss: 0.1024 | Val Loss: 0.1078 | Val MAPE: 0.2142\n",
      "Epoch 33/100 | Train Loss: 0.0980 | Val Loss: 0.1064 | Val MAPE: 0.2128\n",
      "Epoch 34/100 | Train Loss: 0.1023 | Val Loss: 0.1119 | Val MAPE: 0.2342\n",
      "Epoch 35/100 | Train Loss: 0.0978 | Val Loss: 0.1061 | Val MAPE: 0.2092\n",
      "Epoch 36/100 | Train Loss: 0.1007 | Val Loss: 0.1084 | Val MAPE: 0.2162\n",
      "Epoch 37/100 | Train Loss: 0.0992 | Val Loss: 0.1047 | Val MAPE: 0.2108\n",
      "Epoch 38/100 | Train Loss: 0.0976 | Val Loss: 0.1150 | Val MAPE: 0.2289\n",
      "Epoch 39/100 | Train Loss: 0.0981 | Val Loss: 0.1078 | Val MAPE: 0.2195\n",
      "Epoch 40/100 | Train Loss: 0.0953 | Val Loss: 0.1077 | Val MAPE: 0.2164\n",
      "Epoch 41/100 | Train Loss: 0.0952 | Val Loss: 0.1092 | Val MAPE: 0.2221\n",
      "MSE: 0.10923711955547333\n",
      "MAPE: 2.560\n",
      "Epoch 42/100 | Train Loss: 0.0956 | Val Loss: 0.1091 | Val MAPE: 0.2229\n",
      "Epoch 43/100 | Train Loss: 0.0976 | Val Loss: 0.1102 | Val MAPE: 0.2164\n",
      "Epoch 44/100 | Train Loss: 0.0974 | Val Loss: 0.1102 | Val MAPE: 0.2210\n",
      "Epoch 45/100 | Train Loss: 0.0950 | Val Loss: 0.1077 | Val MAPE: 0.2182\n",
      "Epoch 46/100 | Train Loss: 0.0959 | Val Loss: 0.1096 | Val MAPE: 0.2207\n",
      "Epoch 47/100 | Train Loss: 0.0974 | Val Loss: 0.1099 | Val MAPE: 0.2178\n",
      "Epoch 48/100 | Train Loss: 0.0971 | Val Loss: 0.1039 | Val MAPE: 0.2128\n",
      "Epoch 49/100 | Train Loss: 0.0959 | Val Loss: 0.1079 | Val MAPE: 0.2221\n",
      "Epoch 50/100 | Train Loss: 0.0961 | Val Loss: 0.1095 | Val MAPE: 0.2207\n",
      "Epoch 51/100 | Train Loss: 0.0941 | Val Loss: 0.1089 | Val MAPE: 0.2275\n",
      "MSE: 0.10894966870546341\n",
      "MAPE: 2.359\n",
      "Epoch 52/100 | Train Loss: 0.0938 | Val Loss: 0.1060 | Val MAPE: 0.2150\n",
      "Epoch 53/100 | Train Loss: 0.0950 | Val Loss: 0.1150 | Val MAPE: 0.2311\n",
      "Epoch 54/100 | Train Loss: 0.0954 | Val Loss: 0.1232 | Val MAPE: 0.2295\n",
      "Epoch 55/100 | Train Loss: 0.1080 | Val Loss: 0.1183 | Val MAPE: 0.2263\n",
      "Epoch 56/100 | Train Loss: 0.0994 | Val Loss: 0.1114 | Val MAPE: 0.2234\n",
      "Epoch 57/100 | Train Loss: 0.0958 | Val Loss: 0.1067 | Val MAPE: 0.2144\n",
      "Epoch 58/100 | Train Loss: 0.0943 | Val Loss: 0.1049 | Val MAPE: 0.2105\n",
      "Epoch 59/100 | Train Loss: 0.0929 | Val Loss: 0.1119 | Val MAPE: 0.2213\n",
      "Epoch 60/100 | Train Loss: 0.0931 | Val Loss: 0.1062 | Val MAPE: 0.2128\n",
      "Epoch 61/100 | Train Loss: 0.0917 | Val Loss: 0.1097 | Val MAPE: 0.2190\n",
      "MSE: 0.10972821712493896\n",
      "MAPE: 2.494\n",
      "Epoch 62/100 | Train Loss: 0.0917 | Val Loss: 0.1071 | Val MAPE: 0.2175\n",
      "Epoch 63/100 | Train Loss: 0.0917 | Val Loss: 0.1078 | Val MAPE: 0.2190\n",
      "Epoch 64/100 | Train Loss: 0.0926 | Val Loss: 0.1068 | Val MAPE: 0.2164\n",
      "Epoch 65/100 | Train Loss: 0.0914 | Val Loss: 0.1087 | Val MAPE: 0.2210\n",
      "Epoch 66/100 | Train Loss: 0.0925 | Val Loss: 0.1073 | Val MAPE: 0.2174\n",
      "Epoch 67/100 | Train Loss: 0.0915 | Val Loss: 0.1105 | Val MAPE: 0.2166\n",
      "Epoch 68/100 | Train Loss: 0.0910 | Val Loss: 0.1060 | Val MAPE: 0.2111\n",
      "Epoch 69/100 | Train Loss: 0.0903 | Val Loss: 0.1088 | Val MAPE: 0.2165\n",
      "Epoch 70/100 | Train Loss: 0.0895 | Val Loss: 0.1104 | Val MAPE: 0.2291\n",
      "Epoch 71/100 | Train Loss: 0.0875 | Val Loss: 0.1122 | Val MAPE: 0.2283\n",
      "MSE: 0.11218515038490295\n",
      "MAPE: 2.276\n",
      "Epoch 72/100 | Train Loss: 0.0925 | Val Loss: 0.1169 | Val MAPE: 0.2290\n",
      "Epoch 73/100 | Train Loss: 0.0930 | Val Loss: 0.1211 | Val MAPE: 0.2501\n",
      "Epoch 74/100 | Train Loss: 0.0895 | Val Loss: 0.1099 | Val MAPE: 0.2189\n",
      "Epoch 75/100 | Train Loss: 0.0881 | Val Loss: 0.1094 | Val MAPE: 0.2236\n",
      "Epoch 76/100 | Train Loss: 0.0883 | Val Loss: 0.1090 | Val MAPE: 0.2226\n",
      "Epoch 77/100 | Train Loss: 0.0872 | Val Loss: 0.1087 | Val MAPE: 0.2150\n",
      "Epoch 78/100 | Train Loss: 0.0898 | Val Loss: 0.1092 | Val MAPE: 0.2215\n",
      "Epoch 79/100 | Train Loss: 0.0897 | Val Loss: 0.1099 | Val MAPE: 0.2211\n",
      "Epoch 80/100 | Train Loss: 0.0879 | Val Loss: 0.1107 | Val MAPE: 0.2252\n",
      "Epoch 81/100 | Train Loss: 0.0877 | Val Loss: 0.1093 | Val MAPE: 0.2205\n",
      "MSE: 0.10933605581521988\n",
      "MAPE: 2.670\n",
      "Epoch 82/100 | Train Loss: 0.0882 | Val Loss: 0.1089 | Val MAPE: 0.2179\n",
      "Epoch 83/100 | Train Loss: 0.0896 | Val Loss: 0.1138 | Val MAPE: 0.2248\n",
      "Epoch 84/100 | Train Loss: 0.0862 | Val Loss: 0.1083 | Val MAPE: 0.2128\n",
      "Epoch 85/100 | Train Loss: 0.0881 | Val Loss: 0.1098 | Val MAPE: 0.2200\n",
      "Epoch 86/100 | Train Loss: 0.0864 | Val Loss: 0.1142 | Val MAPE: 0.2306\n",
      "Epoch 87/100 | Train Loss: 0.0880 | Val Loss: 0.1120 | Val MAPE: 0.2221\n",
      "Epoch 88/100 | Train Loss: 0.0882 | Val Loss: 0.1111 | Val MAPE: 0.2233\n",
      "Epoch 89/100 | Train Loss: 0.0913 | Val Loss: 0.1097 | Val MAPE: 0.2182\n",
      "Epoch 90/100 | Train Loss: 0.0894 | Val Loss: 0.1103 | Val MAPE: 0.2261\n",
      "Epoch 91/100 | Train Loss: 0.0891 | Val Loss: 0.1120 | Val MAPE: 0.2243\n",
      "MSE: 0.11200843751430511\n",
      "MAPE: 2.430\n",
      "Epoch 92/100 | Train Loss: 0.0902 | Val Loss: 0.1141 | Val MAPE: 0.2253\n",
      "Epoch 93/100 | Train Loss: 0.0874 | Val Loss: 0.1137 | Val MAPE: 0.2356\n",
      "Epoch 94/100 | Train Loss: 0.0865 | Val Loss: 0.1118 | Val MAPE: 0.2267\n",
      "Epoch 95/100 | Train Loss: 0.0865 | Val Loss: 0.1112 | Val MAPE: 0.2235\n",
      "Epoch 96/100 | Train Loss: 0.0844 | Val Loss: 0.1072 | Val MAPE: 0.2183\n",
      "Epoch 97/100 | Train Loss: 0.0830 | Val Loss: 0.1168 | Val MAPE: 0.2239\n",
      "Epoch 98/100 | Train Loss: 0.0840 | Val Loss: 0.1269 | Val MAPE: 0.2456\n",
      "Epoch 99/100 | Train Loss: 0.0885 | Val Loss: 0.1106 | Val MAPE: 0.2248\n",
      "Epoch 100/100 | Train Loss: 0.0894 | Val Loss: 0.1118 | Val MAPE: 0.2255\n",
      "Best model validation loss: 0.1035\n",
      "Training loss: 0.087 with std 0.002\n",
      "Validation loss: 0.113 with std 0.004\n",
      "Validation MAPE: 2.717               with std 0.079\n",
      "\n",
      "Training completed!\n",
      "\n",
      "Testing the trained model...\n",
      "MSE: 0.11181110888719559\n",
      "MAPE: 2.617\n",
      "Final Test MSE: 0.111811\n",
      "Final Test MAPE: 2.617\n",
      "\n",
      "Saving model to: rotary_transformer_world_model.pth\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'WorldModel' object has no attribute 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrotary_transformer_world_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSaving model to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_save_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m \u001b[43mwm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/abiomed/noisy_mujoco/abiomed_env/data_proc/../model.py:539\u001b[0m, in \u001b[0;36mWorldModel.save_model\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, path):\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;66;03m#deepcopy model to cpu before saving\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m     model_copy \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m)\n\u001b[1;32m    540\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model_copy\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstate_dict(), path)\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m model_copy\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1933\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'WorldModel' object has no attribute 'mode'"
     ]
    }
   ],
   "source": [
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load data\n",
    "data_path = '/abiomed/downsampled/10min_1hr_all_data.pkl'\n",
    "print(f\"Loading data from: {data_path}\")\n",
    "\n",
    "with open(data_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(\"Data keys:\", data.keys())\n",
    "print(f\"Train data shape: {data['train'].shape}\")\n",
    "print(f\"Val data shape: {data['val'].shape}\")\n",
    "print(f\"Test data shape: {data['test'].shape}\")\n",
    "print(f\"Number of features: {data['train'].shape[2]}\")\n",
    "\n",
    "# Model parameters\n",
    "num_features = 12  # Number of input features\n",
    "input_horizon = 6\n",
    "forecast_horizon = 6  # Number of time steps to forecast\n",
    "output_dim = (num_features - 1) * forecast_horizon  # Exclude p-level from output\n",
    "    \n",
    "# Create WorldModel with rotary transformer\n",
    "print(\"\\nCreating WorldModel with rotary transformer...\")\n",
    "wm = WorldModel(\n",
    "    num_features=num_features,\n",
    "    dim_model=256,\n",
    "    num_heads=8,\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=2,\n",
    "    encoder_dropout=0.1,\n",
    "    decoder_dropout=0.0,\n",
    "    max_len=100,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    model_type='rotary_transformer',  # Use rotary transformer\n",
    "    device=device\n",
    ")\n",
    "    \n",
    "print(f\"Model created with {num_features} input features\")\n",
    "print(f\"Input horizon: {input_horizon}, Forecast horizon: {forecast_horizon}\")\n",
    "\n",
    "# Load data into the model\n",
    "print(\"\\nLoading data into the model...\")\n",
    "wm.load_data(data_path)\n",
    "print(\"Data loaded successfully!\")\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "print(f\"\\nStarting training with:\")\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining the model...\")\n",
    "best_model = wm.train_model(\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "924367ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing the trained model...\n",
      "Final test mae: 0.20362892746925354\n",
      "Final test MAP mae: 4.100\n",
      "Final Test MAE: 0.203629\n",
      "Final Test MAPE: 4.100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the trained model\n",
    "print(\"\\nTesting the trained model...\")\n",
    "test_mse, test_mape = wm.test(loss='mae')\n",
    "print(f\"Final Test MAE: {test_mse:.6f}\")\n",
    "print(f\"Final Test MAPE: {test_mape:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef246cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model to: /abiomed/downsampled/models/rotary_1hr_mse.pth\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model_save_path = \"/abiomed/downsampled/models/rotary_1hr_mse.pth\"\n",
    "print(f\"\\nSaving model to: {model_save_path}\")\n",
    "wm.save_model(model_save_path)\n",
    "print(f\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0572b060",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create WorldModel with rotary transformer\n",
    "print(\"\\nCreating WorldModel with rotary transformer...\")\n",
    "wm_mae = WorldModel(\n",
    "    num_features=num_features,\n",
    "    dim_model=256,\n",
    "    num_heads=8,\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=2,\n",
    "    encoder_dropout=0.1,\n",
    "    decoder_dropout=0.0,\n",
    "    max_len=100,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    model_type='rotary_transformer',  # Use rotary transformer\n",
    "    device=device\n",
    ")\n",
    "    \n",
    "print(f\"Model created with {num_features} input features\")\n",
    "print(f\"Input horizon: {input_horizon}, Forecast horizon: {forecast_horizon}\")\n",
    "\n",
    "# Load data into the model\n",
    "print(\"\\nLoading data into the model...\")\n",
    "wm_mae.load_data(data_path)\n",
    "print(\"Data loaded successfully!\")\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "print(f\"\\nStarting training with:\")\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining the model...\")\n",
    "best_model = wm_mae.train_model(\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    loss='mae'\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "\n",
    "# Test the trained model\n",
    "print(\"\\nTesting the trained model...\")\n",
    "test_mse, test_mape = wm_mae.test(loss='mae')\n",
    "print(f\"Final Test MAE: {test_mse:.6f}\")\n",
    "print(f\"Final Test MAP MAE: {test_mape:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9379d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8198aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35794de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76275564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59bb2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv /abiomed/downsampled/models/10min_1hr_rotary_model.pth /abiomed/downsampled/models/rotary_1hr_mse2.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48946bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10min_1hr_window_9feat_model.pth   5min_1hr_window_model.pth\n",
      "10min_1hr_window_9feat_model2.pth  5min_2hr_window_model.pth\n",
      "10min_1hr_window_model.pth         rotary_1hr_mse.pth\n",
      "10min_2hr_window_model.pth         rotary_1hr_mse2.pth\n"
     ]
    }
   ],
   "source": [
    "ls /abiomed/downsampled/models/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
