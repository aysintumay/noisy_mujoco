{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d91a0a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "import os, sys\n",
    "# add parent directory to path\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from model import TimeSeriesDataset, TimeSeriesTransformer, TimeSeriesTransformerRotary, WorldModel\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9f3fce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'val', 'test', 'mean', 'std'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('/abiomed/downsampled/10min_1hr_all_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(data.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce2ec0b",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9ff3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load data\n",
    "data_path = '/abiomed/downsampled/10min_1hr_all_data.pkl'\n",
    "print(f\"Loading data from: {data_path}\")\n",
    "\n",
    "with open(data_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(\"Data keys:\", data.keys())\n",
    "print(f\"Train data shape: {data['train'].shape}\")\n",
    "print(f\"Val data shape: {data['val'].shape}\")\n",
    "print(f\"Test data shape: {data['test'].shape}\")\n",
    "print(f\"Number of features: {data['train'].shape[2]}\")\n",
    "\n",
    "# Model parameters\n",
    "num_features = 12  # Number of input features\n",
    "input_horizon = 6\n",
    "forecast_horizon = 6  # Number of time steps to forecast\n",
    "output_dim = (num_features - 1) * forecast_horizon  # Exclude p-level from output\n",
    "    \n",
    "# Create WorldModel with  transformer\n",
    "print(\"\\nCreating WorldModel with transformer...\")\n",
    "wm = WorldModel(\n",
    "    num_features=num_features,\n",
    "    dim_model=256,\n",
    "    num_heads=8,\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=2,\n",
    "    encoder_dropout=0.1,\n",
    "    decoder_dropout=0.0,\n",
    "    max_len=100,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    model_type='transformer',    \n",
    "    device=device\n",
    ")\n",
    "    \n",
    "print(f\"Model created with {num_features} input features\")\n",
    "print(f\"Input horizon: {input_horizon}, Forecast horizon: {forecast_horizon}\")\n",
    "\n",
    "# Load data into the model\n",
    "print(\"\\nLoading data into the model...\")\n",
    "wm.load_data(data_path)\n",
    "print(\"Data loaded successfully!\")\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "print(f\"\\nStarting training with:\")\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining the model...\")\n",
    "best_model = wm.train_model(\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49fc67",
   "metadata": {},
   "source": [
    "# Rotary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8972c979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /abiomed/downsampled/10min_1hr_all_data.pkl\n",
      "Data keys: dict_keys(['train', 'val', 'test', 'mean', 'std'])\n",
      "Train data shape: torch.Size([12051, 12, 13])\n",
      "Val data shape: torch.Size([1938, 12, 13])\n",
      "Test data shape: torch.Size([3876, 12, 13])\n",
      "Number of features: 13\n",
      "\n",
      "Creating WorldModel with rotary transformer...\n",
      "time series transformer device cuda:1\n",
      "Model created with 12 input features\n",
      "Input horizon: 6, Forecast horizon: 6\n",
      "\n",
      "Loading data into the model...\n",
      "loaded datasets with length \n",
      " train:  12051 \n",
      " val:  1938 \n",
      " test:  3876\n",
      "Data loaded successfully!\n",
      "\n",
      "Starting training with:\n",
      "Epochs: 50\n",
      "Batch size: 64\n",
      "Learning rate: 0.001\n",
      "\n",
      "Training the model...\n",
      "New best model with val loss: 0.1503\n",
      "Epoch 1/50 | Train Loss: 0.1753 | Val Loss: 0.1503 | Val MAPE: 0.2734\n",
      "Final test mse: 0.1432153880596161\n",
      "Final test MAP mse: 2.862\n",
      "New best model with val loss: 0.1203\n",
      "Epoch 2/50 | Train Loss: 0.1256 | Val Loss: 0.1203 | Val MAPE: 0.2280\n",
      "New best model with val loss: 0.1146\n",
      "Epoch 3/50 | Train Loss: 0.1185 | Val Loss: 0.1146 | Val MAPE: 0.2137\n",
      "New best model with val loss: 0.1128\n",
      "Epoch 4/50 | Train Loss: 0.1160 | Val Loss: 0.1128 | Val MAPE: 0.2042\n",
      "Epoch 5/50 | Train Loss: 0.1141 | Val Loss: 0.1140 | Val MAPE: 0.2271\n",
      "New best model with val loss: 0.1099\n",
      "Epoch 6/50 | Train Loss: 0.1121 | Val Loss: 0.1099 | Val MAPE: 0.2061\n",
      "New best model with val loss: 0.1045\n",
      "Epoch 7/50 | Train Loss: 0.1100 | Val Loss: 0.1045 | Val MAPE: 0.2038\n",
      "Epoch 8/50 | Train Loss: 0.1108 | Val Loss: 0.1089 | Val MAPE: 0.2047\n",
      "Epoch 9/50 | Train Loss: 0.1103 | Val Loss: 0.1180 | Val MAPE: 0.2282\n",
      "Epoch 10/50 | Train Loss: 0.1083 | Val Loss: 0.1091 | Val MAPE: 0.2143\n",
      "Epoch 11/50 | Train Loss: 0.1072 | Val Loss: 0.1079 | Val MAPE: 0.2113\n",
      "Final test mse: 0.10580022633075714\n",
      "Final test MAP mse: 2.409\n",
      "Epoch 12/50 | Train Loss: 0.1052 | Val Loss: 0.1139 | Val MAPE: 0.2234\n",
      "Epoch 13/50 | Train Loss: 0.1053 | Val Loss: 0.1187 | Val MAPE: 0.2257\n",
      "Epoch 14/50 | Train Loss: 0.1105 | Val Loss: 0.1122 | Val MAPE: 0.2130\n",
      "Epoch 15/50 | Train Loss: 0.1052 | Val Loss: 0.1245 | Val MAPE: 0.2116\n",
      "Epoch 16/50 | Train Loss: 0.1061 | Val Loss: 0.1103 | Val MAPE: 0.2135\n",
      "Epoch 17/50 | Train Loss: 0.1042 | Val Loss: 0.1097 | Val MAPE: 0.2115\n",
      "Epoch 18/50 | Train Loss: 0.1025 | Val Loss: 0.1088 | Val MAPE: 0.2145\n",
      "Epoch 19/50 | Train Loss: 0.1049 | Val Loss: 0.1068 | Val MAPE: 0.2143\n",
      "Epoch 20/50 | Train Loss: 0.1027 | Val Loss: 0.1062 | Val MAPE: 0.2071\n",
      "Epoch 21/50 | Train Loss: 0.1017 | Val Loss: 0.1068 | Val MAPE: 0.2060\n",
      "Final test mse: 0.10455045104026794\n",
      "Final test MAP mse: 2.406\n",
      "Epoch 22/50 | Train Loss: 0.1013 | Val Loss: 0.1057 | Val MAPE: 0.2064\n",
      "Epoch 23/50 | Train Loss: 0.1003 | Val Loss: 0.1071 | Val MAPE: 0.2049\n",
      "Epoch 24/50 | Train Loss: 0.0990 | Val Loss: 0.1146 | Val MAPE: 0.2270\n",
      "Epoch 25/50 | Train Loss: 0.1032 | Val Loss: 0.1088 | Val MAPE: 0.2042\n",
      "Epoch 26/50 | Train Loss: 0.1022 | Val Loss: 0.1098 | Val MAPE: 0.2201\n",
      "Epoch 27/50 | Train Loss: 0.1002 | Val Loss: 0.1072 | Val MAPE: 0.2120\n",
      "Epoch 28/50 | Train Loss: 0.1002 | Val Loss: 0.1054 | Val MAPE: 0.2033\n",
      "Epoch 29/50 | Train Loss: 0.0981 | Val Loss: 0.1144 | Val MAPE: 0.2264\n",
      "Epoch 30/50 | Train Loss: 0.0994 | Val Loss: 0.1120 | Val MAPE: 0.2259\n",
      "Epoch 31/50 | Train Loss: 0.1039 | Val Loss: 0.1126 | Val MAPE: 0.2222\n",
      "Final test mse: 0.11161793023347855\n",
      "Final test MAP mse: 2.269\n",
      "Epoch 32/50 | Train Loss: 0.1013 | Val Loss: 0.1108 | Val MAPE: 0.2135\n",
      "Epoch 33/50 | Train Loss: 0.1000 | Val Loss: 0.1094 | Val MAPE: 0.2073\n",
      "Epoch 34/50 | Train Loss: 0.0981 | Val Loss: 0.1094 | Val MAPE: 0.2114\n",
      "Epoch 35/50 | Train Loss: 0.0975 | Val Loss: 0.1087 | Val MAPE: 0.2111\n",
      "Epoch 36/50 | Train Loss: 0.0980 | Val Loss: 0.1108 | Val MAPE: 0.2143\n",
      "Epoch 37/50 | Train Loss: 0.0982 | Val Loss: 0.1099 | Val MAPE: 0.2129\n",
      "Epoch 38/50 | Train Loss: 0.0963 | Val Loss: 0.1072 | Val MAPE: 0.2120\n",
      "Epoch 39/50 | Train Loss: 0.0961 | Val Loss: 0.1109 | Val MAPE: 0.2163\n",
      "Epoch 40/50 | Train Loss: 0.0969 | Val Loss: 0.1093 | Val MAPE: 0.2187\n",
      "Epoch 41/50 | Train Loss: 0.0959 | Val Loss: 0.1067 | Val MAPE: 0.2045\n",
      "Final test mse: 0.10478290170431137\n",
      "Final test MAP mse: 2.476\n",
      "Epoch 42/50 | Train Loss: 0.0950 | Val Loss: 0.1111 | Val MAPE: 0.2176\n",
      "Epoch 43/50 | Train Loss: 0.0954 | Val Loss: 0.1059 | Val MAPE: 0.2098\n",
      "Epoch 44/50 | Train Loss: 0.0970 | Val Loss: 0.1059 | Val MAPE: 0.2048\n",
      "Epoch 45/50 | Train Loss: 0.0943 | Val Loss: 0.1103 | Val MAPE: 0.2113\n",
      "Epoch 46/50 | Train Loss: 0.0956 | Val Loss: 0.1093 | Val MAPE: 0.2107\n",
      "Epoch 47/50 | Train Loss: 0.0962 | Val Loss: 0.1110 | Val MAPE: 0.2175\n",
      "Epoch 48/50 | Train Loss: 0.0954 | Val Loss: 0.1095 | Val MAPE: 0.2079\n",
      "Epoch 49/50 | Train Loss: 0.0930 | Val Loss: 0.1065 | Val MAPE: 0.2101\n",
      "Epoch 50/50 | Train Loss: 0.0957 | Val Loss: 0.1079 | Val MAPE: 0.2095\n",
      "Best model validation loss: 0.1045\n",
      "Training loss: 0.096 with std 0.001\n",
      "Validation loss: 0.109 with std 0.002\n",
      "Validation MAPE: 2.544               with std 0.051\n",
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load data\n",
    "data_path = '/abiomed/downsampled/10min_1hr_all_data.pkl'\n",
    "print(f\"Loading data from: {data_path}\")\n",
    "\n",
    "with open(data_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(\"Data keys:\", data.keys())\n",
    "print(f\"Train data shape: {data['train'].shape}\")\n",
    "print(f\"Val data shape: {data['val'].shape}\")\n",
    "print(f\"Test data shape: {data['test'].shape}\")\n",
    "print(f\"Number of features: {data['train'].shape[2]}\")\n",
    "\n",
    "# Model parameters\n",
    "num_features = 12  # Number of input features\n",
    "input_horizon = 6\n",
    "forecast_horizon = 6  # Number of time steps to forecast\n",
    "output_dim = (num_features - 1) * forecast_horizon  # Exclude p-level from output\n",
    "    \n",
    "# Create WorldModel with rotary transformer\n",
    "print(\"\\nCreating WorldModel with rotary transformer...\")\n",
    "wm = WorldModel(\n",
    "    num_features=num_features,\n",
    "    dim_model=256,\n",
    "    num_heads=8,\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=2,\n",
    "    encoder_dropout=0.1,\n",
    "    decoder_dropout=0.0,\n",
    "    max_len=100,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    model_type='rotary_transformer',  # Use rotary transformer\n",
    "    device=device\n",
    ")\n",
    "    \n",
    "print(f\"Model created with {num_features} input features\")\n",
    "print(f\"Input horizon: {input_horizon}, Forecast horizon: {forecast_horizon}\")\n",
    "\n",
    "# Load data into the model\n",
    "print(\"\\nLoading data into the model...\")\n",
    "wm.load_data(data_path)\n",
    "print(\"Data loaded successfully!\")\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "print(f\"\\nStarting training with:\")\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining the model...\")\n",
    "best_model = wm.train_model(\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "924367ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing the trained model...\n",
      "Final test mae: 0.20064054429531097\n",
      "Final test MAP mae: 3.835\n",
      "Final Test MAE: 0.200641\n",
      "Final Test MAPE: 3.835\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the trained model\n",
    "print(\"\\nTesting the trained model...\")\n",
    "test_mse, test_mape = wm.test(loss_fn='mae')\n",
    "print(f\"Final Test MAE: {test_mse:.6f}\")\n",
    "print(f\"Final Test MAPE: {test_mape:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ef246cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model to: /abiomed/downsampled/models/rotary_1hr_mse3.pth\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model_save_path = \"/abiomed/downsampled/models/rotary_1hr_mse3.pth\"\n",
    "print(f\"\\nSaving model to: {model_save_path}\")\n",
    "wm.save_model(model_save_path)\n",
    "print(f\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0572b060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating WorldModel with rotary transformer...\n",
      "time series transformer device cuda:1\n",
      "Model created with 12 input features\n",
      "Input horizon: 6, Forecast horizon: 6\n",
      "\n",
      "Loading data into the model...\n",
      "loaded datasets with length \n",
      " train:  12051 \n",
      " val:  1938 \n",
      " test:  3876\n",
      "Data loaded successfully!\n",
      "\n",
      "Starting training with:\n",
      "Epochs: 100\n",
      "Batch size: 64\n",
      "Learning rate: 0.001\n",
      "\n",
      "Training the model...\n",
      "New best model with val loss: 0.2434\n",
      "Epoch 1/100 | Train Loss: 0.2685 | Val Loss: 0.2434 | Val MAPE: 0.3711\n",
      "Final test mae: 0.24355734884738922\n",
      "Final test MAP mae: 4.306\n",
      "New best model with val loss: 0.2197\n",
      "Epoch 2/100 | Train Loss: 0.2082 | Val Loss: 0.2197 | Val MAPE: 0.3470\n",
      "New best model with val loss: 0.2013\n",
      "Epoch 3/100 | Train Loss: 0.1964 | Val Loss: 0.2013 | Val MAPE: 0.3200\n",
      "New best model with val loss: 0.2008\n",
      "Epoch 4/100 | Train Loss: 0.1891 | Val Loss: 0.2008 | Val MAPE: 0.3203\n",
      "Epoch 5/100 | Train Loss: 0.1882 | Val Loss: 0.2055 | Val MAPE: 0.3537\n",
      "New best model with val loss: 0.1956\n",
      "Epoch 6/100 | Train Loss: 0.1843 | Val Loss: 0.1956 | Val MAPE: 0.3173\n",
      "Epoch 7/100 | Train Loss: 0.1832 | Val Loss: 0.2011 | Val MAPE: 0.3343\n",
      "New best model with val loss: 0.1939\n",
      "Epoch 8/100 | Train Loss: 0.1812 | Val Loss: 0.1939 | Val MAPE: 0.3169\n",
      "New best model with val loss: 0.1887\n",
      "Epoch 9/100 | Train Loss: 0.1787 | Val Loss: 0.1887 | Val MAPE: 0.3147\n",
      "Epoch 10/100 | Train Loss: 0.1773 | Val Loss: 0.1954 | Val MAPE: 0.3342\n",
      "Epoch 11/100 | Train Loss: 0.1768 | Val Loss: 0.1897 | Val MAPE: 0.3119\n",
      "Final test mae: 0.18998567759990692\n",
      "Final test MAP mae: 3.764\n",
      "Epoch 12/100 | Train Loss: 0.1760 | Val Loss: 0.1926 | Val MAPE: 0.3130\n",
      "New best model with val loss: 0.1855\n",
      "Epoch 13/100 | Train Loss: 0.1747 | Val Loss: 0.1855 | Val MAPE: 0.3104\n",
      "Epoch 14/100 | Train Loss: 0.1740 | Val Loss: 0.1943 | Val MAPE: 0.3105\n",
      "Epoch 15/100 | Train Loss: 0.1731 | Val Loss: 0.1876 | Val MAPE: 0.3141\n",
      "New best model with val loss: 0.1854\n",
      "Epoch 16/100 | Train Loss: 0.1729 | Val Loss: 0.1854 | Val MAPE: 0.3056\n",
      "Epoch 17/100 | Train Loss: 0.1726 | Val Loss: 0.1883 | Val MAPE: 0.3210\n",
      "Epoch 18/100 | Train Loss: 0.1710 | Val Loss: 0.1906 | Val MAPE: 0.3200\n",
      "Epoch 19/100 | Train Loss: 0.1711 | Val Loss: 0.1913 | Val MAPE: 0.3211\n",
      "Epoch 20/100 | Train Loss: 0.1709 | Val Loss: 0.1859 | Val MAPE: 0.3054\n",
      "New best model with val loss: 0.1846\n",
      "Epoch 21/100 | Train Loss: 0.1707 | Val Loss: 0.1846 | Val MAPE: 0.3047\n",
      "Final test mae: 0.18458594381809235\n",
      "Final test MAP mae: 3.885\n",
      "Epoch 22/100 | Train Loss: 0.1694 | Val Loss: 0.1855 | Val MAPE: 0.3103\n",
      "Epoch 23/100 | Train Loss: 0.1694 | Val Loss: 0.1867 | Val MAPE: 0.3134\n",
      "Epoch 24/100 | Train Loss: 0.1688 | Val Loss: 0.1919 | Val MAPE: 0.3330\n",
      "Epoch 25/100 | Train Loss: 0.1685 | Val Loss: 0.1852 | Val MAPE: 0.3096\n",
      "New best model with val loss: 0.1843\n",
      "Epoch 26/100 | Train Loss: 0.1676 | Val Loss: 0.1843 | Val MAPE: 0.3081\n",
      "Epoch 27/100 | Train Loss: 0.1676 | Val Loss: 0.1884 | Val MAPE: 0.3119\n",
      "Epoch 28/100 | Train Loss: 0.1673 | Val Loss: 0.1863 | Val MAPE: 0.3130\n",
      "Epoch 29/100 | Train Loss: 0.1662 | Val Loss: 0.1878 | Val MAPE: 0.3118\n",
      "Epoch 30/100 | Train Loss: 0.1662 | Val Loss: 0.1874 | Val MAPE: 0.3158\n",
      "Epoch 31/100 | Train Loss: 0.1671 | Val Loss: 0.1870 | Val MAPE: 0.3138\n",
      "Final test mae: 0.18734411895275116\n",
      "Final test MAP mae: 3.875\n",
      "Epoch 32/100 | Train Loss: 0.1651 | Val Loss: 0.1959 | Val MAPE: 0.3294\n",
      "Epoch 33/100 | Train Loss: 0.1653 | Val Loss: 0.1849 | Val MAPE: 0.3143\n",
      "Epoch 34/100 | Train Loss: 0.1648 | Val Loss: 0.1878 | Val MAPE: 0.3207\n",
      "Epoch 35/100 | Train Loss: 0.1651 | Val Loss: 0.1843 | Val MAPE: 0.3096\n",
      "Epoch 36/100 | Train Loss: 0.1643 | Val Loss: 0.1872 | Val MAPE: 0.3163\n",
      "New best model with val loss: 0.1833\n",
      "Epoch 37/100 | Train Loss: 0.1639 | Val Loss: 0.1833 | Val MAPE: 0.3061\n",
      "Epoch 38/100 | Train Loss: 0.1637 | Val Loss: 0.1838 | Val MAPE: 0.3094\n",
      "Epoch 39/100 | Train Loss: 0.1632 | Val Loss: 0.1873 | Val MAPE: 0.3163\n",
      "Epoch 40/100 | Train Loss: 0.1640 | Val Loss: 0.1852 | Val MAPE: 0.3143\n",
      "Epoch 41/100 | Train Loss: 0.1631 | Val Loss: 0.1862 | Val MAPE: 0.3101\n",
      "Final test mae: 0.1860073208808899\n",
      "Final test MAP mae: 3.903\n",
      "Epoch 42/100 | Train Loss: 0.1631 | Val Loss: 0.1852 | Val MAPE: 0.3104\n",
      "Epoch 43/100 | Train Loss: 0.1622 | Val Loss: 0.1853 | Val MAPE: 0.3121\n",
      "Epoch 44/100 | Train Loss: 0.1617 | Val Loss: 0.1846 | Val MAPE: 0.3087\n",
      "Epoch 45/100 | Train Loss: 0.1620 | Val Loss: 0.1854 | Val MAPE: 0.3090\n",
      "Epoch 46/100 | Train Loss: 0.1618 | Val Loss: 0.1873 | Val MAPE: 0.3120\n",
      "Epoch 47/100 | Train Loss: 0.1615 | Val Loss: 0.1852 | Val MAPE: 0.3102\n",
      "Epoch 48/100 | Train Loss: 0.1611 | Val Loss: 0.1842 | Val MAPE: 0.3111\n",
      "Epoch 49/100 | Train Loss: 0.1607 | Val Loss: 0.1846 | Val MAPE: 0.3146\n",
      "Epoch 50/100 | Train Loss: 0.1608 | Val Loss: 0.1869 | Val MAPE: 0.3181\n",
      "Epoch 51/100 | Train Loss: 0.1596 | Val Loss: 0.1845 | Val MAPE: 0.3111\n",
      "Final test mae: 0.1846226304769516\n",
      "Final test MAP mae: 3.984\n",
      "Epoch 52/100 | Train Loss: 0.1606 | Val Loss: 0.1838 | Val MAPE: 0.3113\n",
      "Epoch 53/100 | Train Loss: 0.1602 | Val Loss: 0.1906 | Val MAPE: 0.3299\n",
      "Epoch 54/100 | Train Loss: 0.1597 | Val Loss: 0.1892 | Val MAPE: 0.3208\n",
      "Epoch 55/100 | Train Loss: 0.1589 | Val Loss: 0.1863 | Val MAPE: 0.3114\n",
      "Epoch 56/100 | Train Loss: 0.1599 | Val Loss: 0.1836 | Val MAPE: 0.3105\n",
      "Epoch 57/100 | Train Loss: 0.1629 | Val Loss: 0.1871 | Val MAPE: 0.3132\n",
      "Epoch 58/100 | Train Loss: 0.1601 | Val Loss: 0.1843 | Val MAPE: 0.3144\n",
      "Epoch 59/100 | Train Loss: 0.1585 | Val Loss: 0.1928 | Val MAPE: 0.3189\n",
      "New best model with val loss: 0.1828\n",
      "Epoch 60/100 | Train Loss: 0.1593 | Val Loss: 0.1828 | Val MAPE: 0.3105\n",
      "Epoch 61/100 | Train Loss: 0.1588 | Val Loss: 0.1841 | Val MAPE: 0.3137\n",
      "Final test mae: 0.18363618850708008\n",
      "Final test MAP mae: 3.950\n",
      "Epoch 62/100 | Train Loss: 0.1585 | Val Loss: 0.1848 | Val MAPE: 0.3153\n",
      "Epoch 63/100 | Train Loss: 0.1585 | Val Loss: 0.1879 | Val MAPE: 0.3175\n",
      "Epoch 64/100 | Train Loss: 0.1585 | Val Loss: 0.1834 | Val MAPE: 0.3091\n",
      "Epoch 65/100 | Train Loss: 0.1573 | Val Loss: 0.1877 | Val MAPE: 0.3178\n",
      "New best model with val loss: 0.1820\n",
      "Epoch 66/100 | Train Loss: 0.1576 | Val Loss: 0.1820 | Val MAPE: 0.3098\n",
      "Epoch 67/100 | Train Loss: 0.1579 | Val Loss: 0.1871 | Val MAPE: 0.3187\n",
      "Epoch 68/100 | Train Loss: 0.1573 | Val Loss: 0.1850 | Val MAPE: 0.3127\n",
      "Epoch 69/100 | Train Loss: 0.1577 | Val Loss: 0.1854 | Val MAPE: 0.3134\n",
      "Epoch 70/100 | Train Loss: 0.1570 | Val Loss: 0.1864 | Val MAPE: 0.3178\n",
      "Epoch 71/100 | Train Loss: 0.1565 | Val Loss: 0.1845 | Val MAPE: 0.3118\n",
      "Final test mae: 0.18412727117538452\n",
      "Final test MAP mae: 3.864\n",
      "Epoch 72/100 | Train Loss: 0.1563 | Val Loss: 0.1865 | Val MAPE: 0.3173\n",
      "Epoch 73/100 | Train Loss: 0.1558 | Val Loss: 0.1871 | Val MAPE: 0.3165\n",
      "Epoch 74/100 | Train Loss: 0.1553 | Val Loss: 0.1841 | Val MAPE: 0.3105\n",
      "Epoch 75/100 | Train Loss: 0.1567 | Val Loss: 0.1850 | Val MAPE: 0.3133\n",
      "Epoch 76/100 | Train Loss: 0.1557 | Val Loss: 0.1854 | Val MAPE: 0.3148\n",
      "Epoch 77/100 | Train Loss: 0.1550 | Val Loss: 0.1862 | Val MAPE: 0.3135\n",
      "Epoch 78/100 | Train Loss: 0.1551 | Val Loss: 0.1848 | Val MAPE: 0.3123\n",
      "Epoch 79/100 | Train Loss: 0.1547 | Val Loss: 0.1850 | Val MAPE: 0.3123\n",
      "Epoch 80/100 | Train Loss: 0.1552 | Val Loss: 0.1893 | Val MAPE: 0.3225\n",
      "Epoch 81/100 | Train Loss: 0.1552 | Val Loss: 0.1867 | Val MAPE: 0.3218\n",
      "Final test mae: 0.1866353303194046\n",
      "Final test MAP mae: 3.917\n",
      "Epoch 82/100 | Train Loss: 0.1545 | Val Loss: 0.1873 | Val MAPE: 0.3196\n",
      "Epoch 83/100 | Train Loss: 0.1545 | Val Loss: 0.1859 | Val MAPE: 0.3214\n",
      "Epoch 84/100 | Train Loss: 0.1541 | Val Loss: 0.1873 | Val MAPE: 0.3204\n",
      "Epoch 85/100 | Train Loss: 0.1540 | Val Loss: 0.1860 | Val MAPE: 0.3162\n",
      "Epoch 86/100 | Train Loss: 0.1538 | Val Loss: 0.1875 | Val MAPE: 0.3182\n",
      "Epoch 87/100 | Train Loss: 0.1533 | Val Loss: 0.1843 | Val MAPE: 0.3144\n",
      "Epoch 88/100 | Train Loss: 0.1535 | Val Loss: 0.1893 | Val MAPE: 0.3239\n",
      "Epoch 89/100 | Train Loss: 0.1531 | Val Loss: 0.1879 | Val MAPE: 0.3195\n",
      "Epoch 90/100 | Train Loss: 0.1535 | Val Loss: 0.1863 | Val MAPE: 0.3181\n",
      "Epoch 91/100 | Train Loss: 0.1536 | Val Loss: 0.1898 | Val MAPE: 0.3228\n",
      "Final test mae: 0.18913044035434723\n",
      "Final test MAP mae: 3.928\n",
      "Epoch 92/100 | Train Loss: 0.1532 | Val Loss: 0.1875 | Val MAPE: 0.3227\n",
      "Epoch 93/100 | Train Loss: 0.1528 | Val Loss: 0.1888 | Val MAPE: 0.3311\n",
      "Epoch 94/100 | Train Loss: 0.1526 | Val Loss: 0.1880 | Val MAPE: 0.3230\n",
      "Epoch 95/100 | Train Loss: 0.1526 | Val Loss: 0.1858 | Val MAPE: 0.3170\n",
      "Epoch 96/100 | Train Loss: 0.1522 | Val Loss: 0.1914 | Val MAPE: 0.3357\n",
      "Epoch 97/100 | Train Loss: 0.1521 | Val Loss: 0.1876 | Val MAPE: 0.3191\n",
      "Epoch 98/100 | Train Loss: 0.1521 | Val Loss: 0.1919 | Val MAPE: 0.3380\n",
      "Epoch 99/100 | Train Loss: 0.1534 | Val Loss: 0.1864 | Val MAPE: 0.3192\n",
      "Epoch 100/100 | Train Loss: 0.1528 | Val Loss: 0.1866 | Val MAPE: 0.3184\n",
      "Best model validation loss: 0.1820\n",
      "Training loss: 0.153 with std 0.001\n",
      "Validation loss: 0.188 with std 0.002\n",
      "Validation MAPE: 3.876               with std 0.080\n",
      "\n",
      "Training completed!\n",
      "\n",
      "Testing the trained model...\n",
      "Final test mae: 0.18573342263698578\n",
      "Final test MAP mae: 3.864\n",
      "Final Test MAE: 0.185733\n",
      "Final Test MAP MAE: 3.864\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create WorldModel with rotary transformer\n",
    "print(\"\\nCreating WorldModel with rotary transformer...\")\n",
    "wm_mae = WorldModel(\n",
    "    num_features=num_features,\n",
    "    dim_model=256,\n",
    "    num_heads=8,\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=2,\n",
    "    encoder_dropout=0.1,\n",
    "    decoder_dropout=0.0,\n",
    "    max_len=100,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    model_type='rotary_transformer',  # Use rotary transformer\n",
    "    device=device\n",
    ")\n",
    "    \n",
    "print(f\"Model created with {num_features} input features\")\n",
    "print(f\"Input horizon: {input_horizon}, Forecast horizon: {forecast_horizon}\")\n",
    "\n",
    "# Load data into the model\n",
    "print(\"\\nLoading data into the model...\")\n",
    "wm_mae.load_data(data_path)\n",
    "print(\"Data loaded successfully!\")\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "print(f\"\\nStarting training with:\")\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining the model...\")\n",
    "best_model = wm_mae.train_model(\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    loss_fn='mae'\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "\n",
    "# Test the trained model\n",
    "print(\"\\nTesting the trained model...\")\n",
    "test_mse, test_mape = wm_mae.test(loss_fn='mae')\n",
    "print(f\"Final Test MAE: {test_mse:.6f}\")\n",
    "print(f\"Final Test MAP MAE: {test_mape:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9379d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing the trained model...\n",
      "Final test mae: 0.20836730301380157\n",
      "Final test MAP mae: 3.856\n",
      "Final Test MAE: 0.208367\n",
      "Final Test MAP MAE: 3.856\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the trained model\n",
    "print(\"\\nTesting the trained model...\")\n",
    "test_mse, test_mape = wm.test(loss_fn='mae')\n",
    "print(f\"Final Test MAE: {test_mse:.6f}\")\n",
    "print(f\"Final Test MAP MAE: {test_mape:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8198aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model to: /abiomed/downsampled/models/rotary_1hr_mae.pth\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model_save_path = \"/abiomed/downsampled/models/rotary_1hr_mae.pth\"\n",
    "print(f\"\\nSaving model to: {model_save_path}\")\n",
    "wm.save_model(model_save_path)\n",
    "print(f\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35794de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76275564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59bb2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv /abiomed/downsampled/models/10min_1hr_rotary_model.pth /abiomed/downsampled/models/rotary_1hr_mse2.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48946bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10min_1hr_window_9feat_model.pth   5min_1hr_window_model.pth\n",
      "10min_1hr_window_9feat_model2.pth  5min_2hr_window_model.pth\n",
      "10min_1hr_window_model.pth         rotary_1hr_mse.pth\n",
      "10min_2hr_window_model.pth         rotary_1hr_mse2.pth\n"
     ]
    }
   ],
   "source": [
    "ls /abiomed/downsampled/models/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
